{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2bb9c0",
   "metadata": {},
   "source": [
    "<h1><center>Plan</center></h1>\n",
    "\n",
    "| <h2>Classification</h2> | <h2>Regression</h2> | <h2>Clustering</h2> |\n",
    "| :- | :- | :- |\n",
    "| Neural network (MLP) DONE | Decision tree (LightGBM) DONE | PCA and k-means DONE |\n",
    "| Decision tree (LightGBM) DONE | Neural network (MLP) DONE |  |\n",
    "| kNN DONE| kNN DONE |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3d347",
   "metadata": {},
   "source": [
    "# Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08526595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e14ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        return pd.DataFrame(f[name][:])\n",
    "\n",
    "train = load_data('train')\n",
    "\n",
    "#only consider actual electrons\n",
    "electrons = train[train['Truth'] == True]\n",
    "\n",
    "#only use 15 best features (from SHAP on decision tree)\n",
    "best_features = ['p_eCluster',\n",
    " 'p_eAccCluster',\n",
    " 'p_ecore',\n",
    " 'p_E3x5_Lr1',\n",
    " 'p_rawECluster',\n",
    " 'p_nCells_Lr1_HiG',\n",
    " 'p_eClusterLr1',\n",
    " 'p_deltaEta2',\n",
    " 'p_nTracks',\n",
    " 'p_EptRatio',\n",
    " 'p_d0',\n",
    " 'p_pt_track',\n",
    " 'p_deltaPhi2',\n",
    " 'p_nCells_Lr2_HiG',\n",
    " 'p_deltaEta1']\n",
    "\n",
    "train_variables = electrons[best_features]\n",
    "train_energy = electrons['p_truth_E']\n",
    "train_class = electrons['Truth']\n",
    "\n",
    "#scale data\n",
    "transformer = RobustScaler().fit(train_variables)\n",
    "train_variables = pd.DataFrame(transformer.transform(train_variables), columns=train_variables.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec27c7e",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "### Neural network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0506ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(random_state=42, max_iter=400, solver='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3473cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_variables, train_energy, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16f3f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search_params = {'hidden_layer_sizes': [(15,30,15), (30,30), (40,60), (10,10,10), (100,)],\n",
    "    'activation': ['tanh', 'relu'], 'learning_rate':['constant', 'adaptive']}\n",
    "\n",
    "random_search = RandomizedSearchCV(reg, search_params, n_iter=20, cv=3, return_train_score=True, random_state=42, n_jobs=-1)\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "print('Best parameters: ', random_search.best_params_ , 'Best score: ', random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20dc2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define error function\n",
    "def mape(pred, true):\n",
    "    diffs = abs((true-pred)/true)\n",
    "    \n",
    "    return (sum(diffs))/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e71ba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor error percentage 0.07483129291254882\n"
     ]
    }
   ],
   "source": [
    "#train optimized model\n",
    "reg_opt = MLPRegressor(random_state=42, max_iter=400, solver='adam', hidden_layer_sizes=(40,60), activation='relu', learning_rate='constant')\n",
    "reg_opt.fit(x_train, y_train)\n",
    "y_pred = reg_opt.predict(x_val)\n",
    "error = mape(y_pred, y_val)\n",
    "print('MLPRegressor error '+str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec5987",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78d53a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test = load_data('test')\n",
    "test_variables = test[best_features]\n",
    "\n",
    "#scale data\n",
    "transformer = RobustScaler().fit(test_variables)\n",
    "test_variables = pd.DataFrame(transformer.transform(test_variables), columns=test_variables.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77eb7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply model to test data\n",
    "y_test_pred = pd.DataFrame(reg_opt.predict(test_variables))\n",
    "\n",
    "#export as csv\n",
    "# y_test_pred.to_csv('predicted_energies_MLPRegressor.csv', header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
